---
title: "Site 1 Classification"
author: "Natalie"
date: "2024-08-27"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r load packages, message=F}
library(mlr3)
library(mlr3learners)
library(mlr3spatial)
library(terra)
library(sf)
library(ggplot2)
library(tidyterra)
library(here)
```
# Import Data
Import raster and training polygons
```{r import data}
site1 <- rast(here("Data", "site1", "site1.tif")) #Import the site 1 orthomosaic
site1_poly <- vect(here("Data", "site1", "site1_poly.shp")) #Import the site 1 training polygons
```

# Prepare data for model training
Generate 200 random points within each polygon
```{r create empty spatvector} 
# Create empty spatvector to store the generated points
site1_pts <- vect()
```

```{r generate random points}
#Loop through each polygon in the shapefile
set.seed(101) # The seed is to ensure the same random points are generated each time. The "randomness" refers to the locations where the points are located. 
for (i in 1:nrow(site1_poly)) {
  single_poly <- site1_poly[i, ] #Look in each individual polygon within the training polygons provided
  randomPts <- spatSample(single_poly, 200, method = "random") #Generate 200 randomly placed points within each polygon
  site1_pts <- rbind(site1_pts, randomPts) #Place these random points into the previously created empty spatvector
}
print(site1_pts) #Check to see if the spatvector contains the points 
```
```{r save points}
#Save points as a shapefile (can omit)
writeVector(site1_randomPts, here("Data", "site1", "site1_pts.shp"), filetype = "ESRI Shapefile", overwrite=T) 
```
Note: it is not necessary to save the point shapefile to your computer. I only do it so I have a copy of the files for storage purposes. 

Extract RGB values from the raster at the training points
```{r rename raster layers}
#Rename raster layers
names(site1) <- c("red", "green", "blue") 
```

```{r extract rgb values}
#Extract raster band 1, 2 and 3 (rgb) values at the randomly generated points
site1_extracted <- extract(site1, site1_pts)
```

```{r combine rgb values with point}
#Combine raster values with the point data
site1_pts_rgb <- cbind(site1_pts, site1_extracted) 
#Check if there are any NA values 
sum(is.na(site1_pts_rgb))
#Save the points containing class and rgb values into a geopackage. This can be omitted. 
writeVector(site1_pts_rgb, here("Data", "site1", "site1_pts_rgb.gpkg"), filetype = "GPKG", overwrite = T) 
```

#Model training
Import geopackage
```{r import geopackage}
#The geopackage must be imported using the "read_sf" function for it to work with the classifier 
site1_gpkg <- read_sf(here("Data", "site1", "site1_pts_rgb.gpkg"), stringsAsFactors = T)
#Only keep the 5 columns within the c( ) bracket. 
site1_gpkg <- site1_gpkg[, c("className", "red", "green", "blue", "geom")] 
site1_gpkg
#Check if there are any NA values
sum(is.na(site1_gpkg))
```

Create mlr3 task that will be used in classifying the raster 
```{r task creation}
site1_tsk <- as_task_classif_st(site1_gpkg, target = "className")
```

Partition the data into 70% training and 30% testing.
```{r partition data}
set.seed(100) #To ensure consistency between code runs
#Split the data into 70% training and 30% testing data using the previously created task
site1_split <- partition(site1_tsk, ratio = 0.7) 
```

Create a random forest learner 
```{r create classifier}
site1_lrn <- lrn("classif.ranger")
```

Train the model
```{r train model}
#Train the random forest classifier using the training subset of the data
site1_train <- site1_lrn$train(site1_tsk, site1_split$train)
```

Use the test set to obtain the model's accuracy
```{r test model}
#Test the random forest classifier on the test subset of data
site1_test <- site1_lrn$predict(site1_tsk, site1_split$test)
#Obtain the classification accuracy of the model
site1_test$score(msr("classif.acc"))
```

# Classifying the site and obtaining area and percent coverage 

Apply the learner to the entire raster. This step can take a VERY long time depending on how big your raster is. 
```{r classify raster}
#Apply the classifier to the entire raster so it will classify every pixel based on its rgb values 
site1_classified <- predict_spatial(site1, site1_lrn)
```
Save the classified raster (optional)
```{r save classified raster}
writeRaster(site1_classified, here("Data", "site1", "site1_classified.tif"), overwrite=T)
```

Calculate the area of each class
```{r obtain area per class}
# Obtain the area of each pixel in sq meters
pixel_res <- res(site1_classified)[1] #Obtain the pixel resolution
pixel_area <- pixel_res^2 #Obtain the area of each pixel
```

```{r number of pixels}
# Calculate how many pixels there are in each class and store it in a dataframe
class_frequencies <- freq(site1_classified) 
class_frequencies_df <- as.data.frame(class_frequencies)
```

```{r calculate area}
#calculate area of each class by multiplying pixel area by the number of pixels of each class 
class_frequencies_df$area_m2 <- class_frequencies_df$count * pixel_area
```

Calculate the percent coverage of each class
```{r total raster area}
#get the total area of the raster
total_area_m2 <- sum(class_frequencies_df$area_m2)
```

```{r calculate % coverage}
#calculate percent coverage of each class
class_frequencies_df$percent_coverage <- (class_frequencies_df$area_m2 / total_area_m2) * 100
```

```{r rename classes}
#rename class values for clarity
class_frequencies_df$class <- c("antelope brush", "vegetation", "ground")
```

```{r display}
#display area and percent coverage of each class
print(class_frequencies_df)
```

